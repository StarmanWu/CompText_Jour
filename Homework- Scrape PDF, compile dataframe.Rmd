---
title: 'Homework: Scrape PDF, compile dataframe'
author: "Xingman Wu"
date: "2024-10-25"
output: html_document
---


```{r message=FALSE, warning=FALSE}
#load tidyverse, tidytext, rio 
library(tidyverse)
library(rio)
library(tidytext)
library(pdftools)
```

# Extract the text using the pdftools package
# Split the text so you have one article per file
```{r }
#Using articles downloaded from https://github.com/wellsdata/CompText_Jour/blob/main/exercises/assets/pdfs/AI_yao_taufiq.PDF
#Using pdftools package. 

text <- pdf_text("/Users/xingxing/Downloads/AI_yao_taufiq.PDF")
View(text)
#pdf_text reads the text from a PDF file.
writeLines(text, "AI_text.txt")
#writeLines writes this text to a text file


# Step 2: Combine lines into one single string
text_combined <- paste(text, collapse = "\n")

# Step 3: Split the text by the "End of Document" phrase
documents <- strsplit(text_combined, "End of Document")[[1]]
View(documents)

# Step 4: Write each section to a new file
output_dir <- "../desktop/extracted_text/"
for (i in seq_along(documents)) {
  output_file <- file.path(output_dir, paste0("AI_extracted_", i, ".txt"))
  writeLines(documents[[i]], output_file)
}

cat("Files created:", length(documents), "\n")
# I got 101 individual files in total: the first file is NA, the rest 100 articles are the ones we want.
```



## Construct a dataframe with an index of the articles a unique file name for each article
```{r}
AI_index <- read_lines("AI_text.txt")
x<- AI_index |>
  as.data.frame() # to tell the line number of the content

# Extract lines 18 to 538
extracted_lines <- AI_index[18:538]

# Print the extracted lines to the console
cat(extracted_lines, sep = "\n")

extracted_lines <- extracted_lines |> 
  as.data.frame() 


extracted_lines <- extracted_lines |> 
  mutate(extracted_lines = str_remove(extracted_lines, "\\| About LexisNexis \\| Privacy Policy \\| Terms & Conditions \\| Copyright Â© 2020 LexisNexis"))

View(extracted_lines)
```


## Pull the text articles together into a single dataframe, one row per sentence
```{r}
# Step 1: Trim spaces and detect rows with titles and dates
cleaned_data <- extracted_lines |>
  mutate(
    # Trim leading and trailing spaces before detection
    trimmed_line = str_trim(extracted_lines),  

    # Detect titles (start with a number and a period)
    is_title = str_detect(trimmed_line, "^\\d+\\. "),  

    # Detect dates (e.g., "Aug 14, 2024")
    is_date = str_detect(trimmed_line, "\\b\\w{3} \\d{1,2}, \\d{4}\\b")
  )
View(cleaned_data)

### I found that some of the headlines take up two rows, but I haven't figured out how to detect these types of headlines and combine them with their first line.
### If I could fix this, then the final data would be more reasonable. 

# Step 2: Shift dates to align with corresponding titles
aligned_data <- cleaned_data |>
  mutate(
    date = ifelse(lead(is_date, 1), lead(trimmed_line, 1), NA_character_)  # Shift date to title's row
  ) |>
  filter(is_title) |>
  select(trimmed_line, date)  # Keep only the relevant columns
View(aligned_data)

# Step 3: Rename columns for clarity
final_data <- aligned_data |>
  rename(
    title = trimmed_line,
    date = date
  )
View(final_data)

#Step 4: Date and Publication in separate columns, and formatted
final_data <- separate(data = final_data, col = date, into = c("date2", "publication"), sep = "  ", extra = "merge", fill = "right")


#Step 5: Format date, clean headline
final_data <- final_data |> 
  mutate(date = as.Date(date2,format = "%b %d, %Y")) |> 
  mutate(title =str_remove(title, "^\\d+\\. ")) |> 
  subset(select = -(date2)) |> 
  mutate(index = row_number()) |> 
  select(index, date, title, publication)

```





